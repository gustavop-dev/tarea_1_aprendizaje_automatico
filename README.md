# Experimentos de B√∫squeda de Hiperpar√°metros - Tarea 1

Este repositorio contiene los experimentos de b√∫squeda de hiperpar√°metros para la Tarea 1 del primer parcial de Aprendizaje Autom√°tico.

## üìÅ Estructura del Proyecto

```
‚îú‚îÄ‚îÄ busqueda de hiperparametros.ipynb    # Notebook base con GridSearchCV y RandomizedSearchCV
‚îú‚îÄ‚îÄ experimento_optuna.py                # Experimento con Optuna
‚îú‚îÄ‚îÄ ejecutar_experimentos.py             # Script para ejecutar todos los experimentos
‚îú‚îÄ‚îÄ requirements.txt                     # Dependencias del proyecto
‚îî‚îÄ‚îÄ README.md                           # Este archivo
```

## üöÄ Instalaci√≥n

1. **Crear un entorno virtual (recomendado):**
```bash
python -m venv venv
source venv/bin/activate  # En Linux/Mac
venv\Scripts\activate     # En Windows
```

2. **Instalar las dependencias:**
```bash
pip install -r requirements.txt
```

## üìä Descripci√≥n de los Experimentos

### 1. Notebook Base: `busqueda de hiperparametros.ipynb`
- **M√©todos implementados:** GridSearchCV y RandomizedSearchCV
- **Algoritmo:** DecisionTreeClassifier
- **Dataset:** Breast Cancer Wisconsin (Diagnostic)
- **Caracter√≠sticas:**
  - Comparaci√≥n detallada entre ambos m√©todos
  - An√°lisis de convergencia
  - Evaluaci√≥n en conjunto de prueba
  - Documentaci√≥n completa en espa√±ol

### 2. Experimento con Optuna: `experimento_optuna.py`
- **Framework:** Optuna (optimizaci√≥n bayesiana moderna)
- **Algoritmo de optimizaci√≥n:** TPE (Tree-structured Parzen Estimator)
- **Caracter√≠sticas:**
  - B√∫squeda inteligente de hiperpar√°metros
  - Visualizaci√≥n de convergencia
  - Comparaci√≥n con m√©todos tradicionales
  - An√°lisis de eficiencia

#### üî¨ **¬øQu√© hace este experimento?**
Este experimento es una **comparaci√≥n educativa** entre tres m√©todos de b√∫squeda de hiperpar√°metros:

1. **GridSearchCV (M√©todo tradicional exhaustivo):**
   - Prueba TODAS las combinaciones posibles (72 combinaciones)
   - Garantiza encontrar la mejor combinaci√≥n en el espacio definido
   - Muy lento para espacios grandes

2. **RandomizedSearchCV (M√©todo tradicional aleatorio):**
   - Prueba 50 combinaciones aleatorias
   - M√°s r√°pido que GridSearch
   - Puede perderse buenas combinaciones por suerte

3. **Optuna (M√©todo moderno con optimizaci√≥n bayesiana):**
   - Ejecuta 100 trials inteligentes
   - **Aprende de intentos anteriores** usando TPE
   - Sugiere par√°metros prometedores bas√°ndose en resultados previos
   - Balance √≥ptimo entre velocidad y precisi√≥n

#### üéØ **Proceso del experimento:**
1. Carga el dataset de c√°ncer de mama (569 muestras, 30 caracter√≠sticas)
2. Entrena DecisionTreeClassifier con cada m√©todo
3. Mide tiempo de ejecuci√≥n y precisi√≥n de cada m√©todo
4. Eval√∫a todos los modelos en conjunto de prueba
5. Genera visualizaciones de convergencia y comparaciones
6. Produce un reporte completo con conclusiones

#### üìà **Resultados esperados:**
- **GridSearchCV**: M√°s lento pero exhaustivo
- **RandomizedSearchCV**: M√°s r√°pido pero menos preciso
- **Optuna**: Mejor balance velocidad/precisi√≥n, convergencia inteligente

## üîß C√≥mo Ejecutar los Experimentos

### Opci√≥n 1: Script Interactivo (Recomendado)
```bash
python ejecutar_experimentos.py
```
Este script te permite:
- Abrir el notebook interactivo
- Ejecutar el experimento con Optuna
- Ver archivos generados
- Verificar dependencias

### Opci√≥n 2: Notebook Interactivo
```bash
jupyter notebook "busqueda de hiperparametros.ipynb"
```
Ejecuta todas las celdas paso a paso para ver la comparaci√≥n entre GridSearchCV y RandomizedSearchCV.

### Opci√≥n 3: Experimento con Optuna Directo
```bash
python experimento_optuna.py
```
Este experimento ejecutar√°:
- GridSearchCV (referencia)
- RandomizedSearchCV (referencia)
- Optuna con 100 trials
- An√°lisis comparativo completo

## üìà Resultados Esperados

### Archivos de Salida
Los experimentos generar√°n los siguientes archivos:

**Experimento Optuna:**
- `optuna_convergencia.png` - An√°lisis de convergencia
- `comparacion_metodos.png` - Comparaci√≥n entre m√©todos

### M√©tricas Evaluadas
- **Accuracy:** Exactitud en validaci√≥n cruzada y conjunto de prueba
- **F1-Score:** Puntaje F1 en conjunto de prueba
- **Tiempo de ejecuci√≥n:** Eficiencia computacional
- **N√∫mero de evaluaciones:** Cantidad de combinaciones probadas

## üéØ Puntos Clave del Experimento

### M√©todos Comparados
1. **GridSearchCV:** B√∫squeda exhaustiva (m√©todo tradicional)
2. **RandomizedSearchCV:** B√∫squeda aleatoria (m√©todo tradicional)
3. **Optuna:** Optimizaci√≥n bayesiana moderna

### Ventajas de Optuna
- **Algoritmo TPE avanzado:** M√°s eficiente que la b√∫squeda aleatoria
- **Interfaz moderna:** F√°cil de usar y configurar
- **Visualizaciones integradas:** An√°lisis autom√°tico de convergencia
- **Pruning autom√°tico:** Detiene trials malos temprano
- **Escalabilidad:** Maneja espacios de b√∫squeda complejos

### Conclusiones Esperadas
El framework de optimizaci√≥n bayesiana (Optuna) generalmente:
- **Encuentra mejores hiperpar√°metros** que la b√∫squeda aleatoria
- **Es m√°s eficiente** que la b√∫squeda exhaustiva
- **Converge m√°s r√°pidamente** a buenas soluciones
- **Permite explorar espacios de b√∫squeda m√°s complejos**

#### üéì **Valor educativo del experimento:**
- **Demuestra la evoluci√≥n** de los m√©todos de ML: de exhaustivos a inteligentes
- **Compara m√©tricas reales**: tiempo, precisi√≥n, eficiencia computacional
- **Visualiza la convergencia**: c√≥mo Optuna aprende y mejora con cada trial
- **Proporciona evidencia emp√≠rica** de por qu√© los m√©todos bayesianos son superiores
- **Prepara para problemas reales**: donde los espacios de b√∫squeda son enormes

## üõ†Ô∏è Personalizaci√≥n

### Modificar Par√°metros del Experimento
Puedes ajustar los siguientes par√°metros en `experimento_optuna.py`:

```python
# N√∫mero de trials para Optuna
n_trials = 100

# Espacio de b√∫squeda para DecisionTree
search_space = {
    'max_depth': [3, 5, 7, 10, 12, 15, 18, 20],
    'min_samples_split': [2, 5, 10, 15, 20],
    'min_samples_leaf': [1, 2, 4, 6, 8],
    'criterion': ['gini', 'entropy']
}
```

### Cambiar el Algoritmo de ML
Los experimentos est√°n configurados para DecisionTree, pero puedes cambiar a otros algoritmos modificando las funciones objetivo.

### Agregar Nuevas M√©tricas
Puedes agregar nuevas m√©tricas de evaluaci√≥n modificando la funci√≥n `evaluar_modelos()`.

## üîç An√°lisis de Resultados

### Interpretaci√≥n de Gr√°ficos
- **Convergencia:** Muestra c√≥mo mejora el mejor puntaje a lo largo de los trials
- **Distribuci√≥n:** Histograma de todos los puntajes obtenidos
- **Comparaci√≥n:** Barras comparativas entre m√©todos

### M√©tricas de Eficiencia
- **Eficiencia = Accuracy / Tiempo**
- **Mejores par√°metros:** Combinaci√≥n √≥ptima encontrada
- **Puntaje CV:** Rendimiento en validaci√≥n cruzada
- **Puntaje Test:** Rendimiento en conjunto de prueba

## üìù Notas Adicionales

### Reproducibilidad
Todos los experimentos usan semillas fijas (`random_state=42`) para garantizar resultados reproducibles.

### Recursos Computacionales
Los experimentos est√°n optimizados para usar m√∫ltiples n√∫cleos (`n_jobs=-1`) cuando sea posible.

### Extensiones Futuras
- Agregar m√°s algoritmos de ML
- Implementar validaci√≥n cruzada estratificada
- Incluir m√©tricas adicionales (precision, recall, AUC)
- Probar con otros datasets

## ü§ù Contribuciones

Este proyecto es parte de una tarea acad√©mica. Las mejoras y extensiones son bienvenidas.

## üìö Referencias

- [Optuna Documentation](https://optuna.org/)
- [Scikit-learn Documentation](https://scikit-learn.org/)
- [Breast Cancer Wisconsin Dataset](https://scikit-learn.org/stable/datasets/toy_dataset.html#breast-cancer-dataset)

---

**Autor:** Tarea 1 - Primer Parcial  
**Curso:** Aprendizaje Autom√°tico  
**Dataset:** Breast Cancer Wisconsin (Diagnostic) 